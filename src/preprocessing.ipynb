{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add our splits to lincs_adata.h5ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "lincs_adata = sc.read('data/lincs_adata.h5ad')\n",
    "my_split = pd.read_pickle('data/Lincs_mysplit.pkl')\n",
    "lincs_adata.obs['dose_val_4f'] = round(lincs_adata.obs.dose,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lincs_adata.obs['my_split'] = my_split.copy()\n",
    "lincs_adata.obs['my_split'] = lincs_adata.obs['my_split'].apply(lambda x: 'valid' if x == 'test' else x)\n",
    "lincs_adata.obs['Both_unseen'] = lincs_adata.obs['my_split'].apply(lambda x: 'test' if x == 'val_both_unseen' else x)\n",
    "lincs_adata.obs['Drug_unseen'] = lincs_adata.obs['my_split'].apply(lambda x: 'test' if x == 'val_drug_unseen' else x)\n",
    "lincs_adata.obs['Cell_line_unseen'] = lincs_adata.obs['my_split'].apply(lambda x: 'test' if x == 'val_cell_line_unseen' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(lincs_adata.obs['my_split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lincs_adata.write_h5ad('data/lincs_adata.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate text embeddings for drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_smiles = list(lincs_adata.obs['SMILES'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained MolT5\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"laituan245/molt5-large-smiles2caption\", model_max_length=512)\n",
    "model = T5ForConditionalGeneration.from_pretrained('laituan245/molt5-large-smiles2caption')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SMILES caption using MolT5\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "smiles_caption = {}\n",
    "device=torch.device('cuda:0')\n",
    "model=model.to(device)\n",
    "with torch.no_grad():\n",
    "    for smile in tqdm(all_smiles):\n",
    "        input_ids = tokenizer(smile, return_tensors=\"pt\").input_ids.to(device)\n",
    "        outputs = model.generate(input_ids, num_beams=5, max_length=512)\n",
    "        smiles_caption[smile]=tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained BioLinkBERT\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('michiyasunaga/BioLinkBERT-large')\n",
    "model = AutoModel.from_pretrained('michiyasunaga/BioLinkBERT-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text embedding using BioLinkBERT\n",
    "smiles_text_emb = {}\n",
    "device=torch.device('cpu')\n",
    "model=model.to(device)\n",
    "with torch.no_grad():\n",
    "    for k,v in tqdm(smiles_caption.items()):\n",
    "        inputs = tokenizer(v, return_tensors=\"pt\").to(device)\n",
    "        outputs = model(**inputs)\n",
    "        smiles_text_emb[k]=outputs.last_hidden_state.detach().squeeze(0).cpu()\n",
    "torch.save(smiles_text_emb, 'data/pert_smiles_emb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dosage prompt\n",
    "dose_val = lincs_adata.obs['dose_val_4f'].unique()\n",
    "dosage_prompt = {}\n",
    "for i in dose_val:\n",
    "    dosage_prompt[i]='The dosage is '+i.astype(str)+' micromoles.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dosage_prompt_emb = {}\n",
    "with torch.no_grad():\n",
    "    for k,v in dosage_prompt.items():\n",
    "        inputs = tokenizer(v, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs)\n",
    "        dosage_prompt_emb[k]=outputs.last_hidden_state.detach().squeeze(0).cpu()\n",
    "torch.save(dosage_prompt_emb, 'data/dosage_prompt_emb_lincs.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
